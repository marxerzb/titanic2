---
title: "R Notebook"
output: html_notebook
---

A Titanic katasztrófa túlélésének predikciója
=============================================


Könyvtárak:
```{r}
  library(readr)
  library(mice)
  library(caret)
  library(splines)
  library(glmnet)
  library(nnet)
  library(rpart)
  library(randomForest)
  library(gbm)
  library(caretEnsemble)
  library(ModelMetrics)
  library(plotmo)
  library(plyr)
  library(ggplot2)
  library(gmodels)
  library(xgboost)
  library(earth)
  library(e1071)
  library(hrbrthemes)
  library(rattle)
  library(reshape2)
  library(plyr)
  library(XML)
  library(pROC)
```

Adatok beolvasása, előkészítése:
```{r}
  train <- read_csv("train.csv", 
       col_types = cols(
           Sex = col_factor(levels = c("male", "female")),
           Age = col_double(), 
           Embarked = col_factor(levels = c("C", "S", "Q")), 
           Parch = col_integer(), 
           Pclass = col_factor(levels = c("3", "2", "1"), ordered = TRUE), 
           SibSp = col_integer(), 
           Survived = col_integer()))
  test <- read_csv("test.csv", 
       col_types = cols(
           Sex = col_factor(levels = c("male", "female")),
           Age = col_double(), 
           Embarked = col_factor(levels = c("C", "S", "Q")), 
           Parch = col_integer(), 
           Pclass = col_factor(levels = c("3", "2", "1"), ordered = TRUE), 
           SibSp = col_integer()))
  
  traink <- dummyVars("~ Sex + Embarked", data = train)
  traink <- data.frame(predict(traink, newdata = train))
  traink$Pclass <- train$Pclass
  traink$Age <- train$Age
  traink$SibSp <- train$SibSp
  traink$Parch <- train$Parch
  traink$Fare <- train$Fare
  traink$Survived <- train$Survived
  set.seed(1912)
  traink <- complete(mice(traink, method="rf", m=1))
  
  y <- traink$Survived
  X <- model.matrix(Survived~., data=traink)
  X <- X[,c("Sex.male", "Sex.female", "Embarked.C", "Embarked.S", "Embarked.Q", "Pclass.L", "Pclass.Q", "Age", "SibSp", "Parch", "Fare")]
  
  sample1 <- sort(sample(c(1:891), size=600, replace=F), decreasing=F)
  X1 <- X[sample1,]
  X2 <- X[-sample1,]
  y1 <- y[sample1]
  y2 <- y[-sample1]
  
  Xvesz<-data.frame(cbind(X1,Survived=y1))
```

Kimutatások, leíró statisztikák, diagramok:
```{r}
  CrossTable(traink$Survived, traink$Sex.female)
  ggplot(data=traink, aes(Age))+geom_histogram(fill="darkblue", color = "yellow") +xlab("Kor") +ylab("Lélekszám") +labs(title="Kor-lélekszám diagram")
  ggplot(data=traink, aes(as.factor(round(Age)))) +geom_bar(data=subset(traink,Sex.female==1), aes(y=..count..*(-1)), fill="deeppink", color="deeppink") +geom_bar(data=subset(traink,Sex.female==0), fill="deepskyblue", color="deepskyblue") +scale_y_continuous(breaks=seq(-40,40,10),labels=abs(seq(-40,40,10))) +coord_flip()+xlab("Kor") +ylab("Lélekszám") +labs(title="Az utasok korfája")
  ggplot(data=traink, aes(log(Fare+1)))+geom_histogram(fill="darkblue", color="yellow") +xlab("log-menetdíj") +ylab("Darabszám") +labs(title="log-menetdíjak megoszlása")
  ggplot(data=traink, aes(Survived))+geom_bar(fill="darkblue")
  ggplot(data=traink, aes(x=as.factor(Survived), y=Age, color=Survived))+geom_boxplot(fill="yellow", color="darkblue") +xlab("Túlélés") +ylab("Kor") +labs(title="Életkor megoszlása a túlélés függvényében")
```

LOGIT-modell:
```{r}
  logit_reg <- glm(Survived~., data=Xvesz, family=binomial(link="logit"))
  predlogit <- predict(logit_reg, data.frame(X2), type="response")
  roc(y2 ~ predlogit, plot = TRUE, print.auc = TRUE)
  
  acc=seq(0, 1, by=0.01)
  err_logit <- rep(NA, length(acc))
  for(i in 1:length(acc)){
    pred <- predlogit > acc[i]
    err_logit[i] <- RMSE(pred, y2)
  }
  min(err_logit)
  binpredlogit<-predlogit>acc[which.min(err_logit)]
  CrossTable(binpredlogit, y2)
```

LASSO-modell:
```{r}
  Lasso_reg<-cv.glmnet(X1, y1, alpha=1)
  plot(Lasso_reg)
  best_lam<-Lasso_reg$lambda.1se
  
  Lasso_best <- glmnet(X1, y1, alpha = 1, lambda = best_lam)
  predlasso <- predict(Lasso_best, s = best_lam, newx = X2)
  coefficients(Lasso_best)
  
  err_lasso <- rep(NA, length(acc))
  for(i in 1:length(acc)){
    pred <- predlasso > acc[i]
    err_lasso[i] <- RMSE(pred, y2)
  }
  min(err_lasso)
  binpredlasso<-predlasso>acc[which.min(err_lasso)]
  CrossTable(binpredlasso, y2)
```

Spline-függvényes megközelítés:
```{r}
  spline_reg=lm(Survived~Sex.male+Sex.female+Embarked.C+Embarked.S+Embarked.Q+Pclass.L+Pclass.Q+bs(Age)+SibSp+Parch+bs(Fare), data=Xvesz)
  summary(spline_reg)
  plotmo(spline_reg)
  predspline<-predict(spline_reg, data.frame(X2))
  
  err_spline <- rep(NA, length(acc))
  for(i in 1:length(acc)){
    pred <- predspline > acc[i]
    err_spline[i] <- RMSE(pred, y2)
  }
  min(err_spline)
  binpredspline<-predspline>acc[which.min(err_spline)]
  CrossTable(binpredspline, y2)
```

Spline-függvényes megközelítés LASSO-val szűrve:
```{r}
  X1_spline<-predict(spline_reg, data.frame(X1))
  Splasso_reg<-cv.glmnet(X1, X1_spline, alpha=1)
  plot(Splasso_reg)
  best_lam<-Splasso_reg$lambda.1se
  
  Splasso_best <- glmnet(X1, X1_spline, alpha = 1, lambda = best_lam)
  predsplasso <- predict(Splasso_best, s = best_lam, newx = X2)
  coefficients(Splasso_best)
  
  acc=seq(0, 1, by=0.01)
  err_splasso <- rep(NA, length(acc))
  for(i in 1:length(acc)){
    pred <- predsplasso > acc[i]
    err_splasso[i] <- RMSE(pred, y2)
  }
  min(err_splasso)
  binpredsplasso<-predsplasso>acc[which.min(err_splasso)]
  CrossTable(binpredsplasso, y2)
```

MARS-modellek különböző fokok mellett:
```{r}
  deg=seq(1,5,by=1)
  err_marsok=rep(NA, length(deg))
  for(j in 1:length(deg)){
    Mars<-earth(Survived~., data=Xvesz, degree=deg[j])
    summary(Mars)
  
    plotmo(Mars)
    predmars<-predict(Mars, X2)
  
    err_mars <- rep(NA, length(acc))
    for(i in 1:length(acc)){
      pred <- predmars > acc[i]
      err_mars[i] <- RMSE(pred, y2)
    }
    err_marsok[j]=min(err_mars)
  }
  plot(err_marsok, ylab="R-érték", xlab="degree-érték", col="blue", type="l")
```

MARS(degree=3)-modell:
```{r}
  Mars3<-earth(Survived~., data=Xvesz, degree=3)
  summary(Mars3)
  plotmo(Mars3)
  predmars3<-predict(Mars3, X2)
  
  err_mars3 <- rep(NA, length(acc))
  for(i in 1:length(acc)){
    pred <- predmars3 > acc[i]
    err_mars3[i] <- RMSE(pred, y2)
  }
  min(err_mars3)
  binpredmars3<-predmars3>acc[which.min(err_mars3)]
  CrossTable(binpredmars3, y2)
```

Családkalkulátor
```{r}
  reka <- c(0, 1, 0, 1, 0, -0.7071068, 0.4082483, 20, 1, 0, 6.00)
  predreka<-predict(Mars3, reka)
  binpredreka<-predreka>acc[which.min(err_mars3)]
  binpredreka
```

SVM-modell:
```{r}
  SVM <- svm(as.factor(Survived)~., data=Xvesz, scale=TRUE)
  plot(SVM, Age~Fare, data=Xvesz)
  
  racs1 <- expand.grid(C=2^seq(from=0, to=6, by=0.5), sigma=10^seq(from=-3, to=0, by=0.5))
  finomh1 <- train(as.factor(Survived)~., data=Xvesz, method="svmRadial", tuneGrid=racs1)
  finomh_eredmeny1 <- finomh1$results
  summary(finomh_eredmeny1)
  finomh1
  ggplot(finomh_eredmeny1, aes(x=log2(C), y=log10(sigma), fill=Accuracy), col="red")+geom_tile()+scale_fill_gradient(low="white", high="darkgreen")+geom_vline(xintercept = 2.5)+geom_vline(xintercept = 3.5)+geom_hline(yintercept = -2)+geom_hline(yintercept = -1)
  
  racs2 <- expand.grid(C=2^seq(from=2.5, to=3.5, by=0.1), sigma=10^seq(from=-2, to=-1, by=0.1))
  finomh2 <- train(as.factor(Survived)~., data=Xvesz, method="svmRadial", tuneGrid=racs2)
  finomh_eredmeny2 <- finomh2$results
  summary(finomh_eredmeny2)
  finomh2
  ggplot(finomh_eredmeny2, aes(x=log2(C), y=log10(sigma), fill=Accuracy), col="red")+geom_tile()+scale_fill_gradient(low="orange", high="blue")+geom_vline(xintercept = 2.8)+geom_vline(xintercept = 3)+geom_hline(yintercept = -1.3)+geom_hline(yintercept = -1.1)
```

Véletlen erdő:
```{r}
  keresztval <- trainControl(method="cv", number=5)
  fa <- train(as.factor(Survived)~., data=traink, method="rpart", trControl=keresztval)
 fa # cp=0.01461988 esetén Accuracy=0.8002134, Kappa=0.5708988
 #plot(fa$finalModel)
 #text(fa$finalModel)
 fancyRpartPlot(fa$finalModel)
```

```{r}
  mtry <- data.frame(mtry=1:10)
  erdo <- train(as.factor(Survived)~., data=traink, method="rf", trControl=keresztval, ntree=30, tuneGrid=mtry)
  erdo # mtry=4 esetén Accuracy=0.8440274, Kappa=0.6614112
  plot(erdo$finalModel) # ez nem rendes erdőrajz, de olyat careten belül nem találtam
  
  erdo$finalModel
```

```{r}
  gboost <- train(as.factor(Survived)~., data=traink, method="gbm", trControl=keresztval)
  gboost # n.trees = 150, interaction.depth = 2, shrinkage = 0.1 and n.minobsinnode = 10 esetén Accuracy=0.8249262, Kappa=0.6225874
```

```{r}
  hyper <- data.frame(n.trees = 150, interaction.depth = 2, shrinkage = 0.1, n.minobsinnode = 10)
  gboost_best <- train(as.factor(Survived)~., data=traink, method="gbm", trControl=keresztval, tuneGrid=hyper)
  mtry <- data.frame(mtry=4)
  erdo_best <- train(as.factor(Survived)~., data=traink, method="rf", trControl=keresztval, ntree=30, tuneGrid=mtry)
  summary(gboost_best)
  gboost_best # Accuracy=0.8248481, Kappa=0.6215871
  summary(erdo_best)
  erdo_best # Accuracy=0.8384265, Kappa=0.6501237
```

Változók fontossága, becslés
```{r}
  fontos_gboost <- varImp(gboost_best)
  fontos_gboost <- fontos_gboost$importance
  plot(varImp(gboost_best))

  fontos_erdo <- varImp(erdo_best)
  fontos_erdo <- fontos_erdo$importance
  plot(varImp(erdo_best))
```

==================================================
Ezek átírandók!!!
```{r}
  becsultgb <- predict(gboost_best, testk)
  CrossTable(becsultgb,gender_submission$Survived)
```

```{r}
becsulterdo <- predict(erdo_best, testk)
  CrossTable(becsulterdo,gender_submission$Survived)
```

Benedeké:
```{r}
  library(readr)
  gender_submission <- read.csv("gender_submission.csv")
  View(gender_submission)
  train <- read_csv("train.csv", 
       col_types = cols(
           Sex = col_factor(levels = c("male", "female")),
           Age = col_double(), 
           Embarked = col_factor(levels = c("C", "S", "Q")), 
           Parch = col_integer(), 
           Pclass = col_factor(levels = c("3", "2", "1"), ordered = TRUE), 
           SibSp = col_integer(), 
           Survived = col_integer()))
  test <- read_csv("test.csv", 
       col_types = cols(
           Sex = col_factor(levels = c("male", "female")),
           Age = col_double(), 
           Embarked = col_factor(levels = c("C", "S", "Q")), 
           Parch = col_integer(), 
           Pclass = col_factor(levels = c("3", "2", "1"), ordered = TRUE), 
           SibSp = col_integer()))
  View(test)
```

```{r}
  # adatok one-hot kódolása
  
  newdata <- dummyVars("~ Pclass + Sex + Embarked", data = train)
  train_data <- data.frame(predict(newdata, newdata = train))
  train_data$Age <- train$Age
  train_data$SibSp <- train$SibSp
  train_data$Parch <- train$Parch
  train_data$Fare <- train$Fare
  train_data$Family <- train$SibSp + train$Parch
  View(train_data)
  
  # xgboost modellhez DMatrix szükséges, mind a tanuló, mind a teszthalmazhoz
  
  train_dmatrix <- xgb.DMatrix(label = train$Survived, data = as.matrix(train_data))
  
  
  newtest <- dummyVars("~ Pclass + Sex + Embarked", data = test)
  test_data <- data.frame(predict(newtest, newdata = test))
  test_data$Age <- test$Age
  test_data$SibSp <- test$SibSp
  test_data$Parch <- test$Parch
  test_data$Fare <- test$Fare
  test_data$Family <- test$SibSp + test$Parch
  View(test_data)
  
  test_dmatrix <- xgb.DMatrix(data = as.matrix(test_data))
  
  # kezdetleges xgboost
  
  xgbmodel <- xgboost(data = train_dmatrix, max.depth = 2, eta = 1, nthread = 2, nrounds = 10, objective = "binary:logistic")
  
  # paraméter tuningolás (randomsearch) -> túl sok paraméter, globális optimum megtalálása túl "költséges" -> a véletlent hívjuk segítségül
  
  start_time <- Sys.time()
  
  best_param <- list()
  best_acc <- 0
  best_acc_index <- 0
  
  for (iter in 1:1000) {
    # a modell paramétereinek listája, ezeket szeretnénk tuningolni
    param_list <- list(objective = "binary:logistic",  #binary:logistic, binary:hinge
                  eval_metric = c("error"),      
                  max_depth = sample(3:10, 1),
                  eta = runif(1, .01, .3),   
                  subsample = runif(1, .6, .9),
                  colsample_bytree = runif(1, .6, .9), 
                  min_child_weight = sample(5:10, 1), 
                  max_delta_step = sample(1:10, 1),
                  base_score = runif(1, .3, .6)
                  )
    xgb_cv <- xgb.cv(data = train_dmatrix, booster = "gbtree", params = param_list,  
                   nfold = 10, nrounds = 20,
                   verbose = F, early_stopping_rounds = 20, maximize = FALSE,
                   stratified = T)
  
    max_acc_index  <-  xgb_cv$best_iteration
    max_acc <- 1 - xgb_cv$evaluation_log[xgb_cv$best_iteration]$test_error_mean
  
    #print(max_acc)
    #print(xgb_cv$evaluation_log[xgb_cv$best_iteration])
  
    # keressük a legpontosabb paramétereket
    if (max_acc > best_acc) {
      best_acc <- max_acc
      best_acc_index <- max_acc_index
      best_param <- param_list
    }
    
    if (max_acc < .7){
      print(param_list)
    }
  }
  
  end_time <- Sys.time()
  
  print(end_time - start_time)
  
  print(best_acc)
  print(best_param)
```
